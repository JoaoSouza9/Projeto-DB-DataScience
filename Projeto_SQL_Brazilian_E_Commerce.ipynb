{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Projeto SQL - Brazilian E-Commerce Public Dataset\n",
        "Análise Exploratória de Dados de Vendas Online\n",
        "\n",
        "1. Do objetivo:\n",
        "\n",
        "    Realizar uma análise exploratória de dados de vendas online, utilizando um conjunto de dados real (Brazilian E-Commerce Public Dataset), a fim de extrair insights e entender melhor o fenômeno das vendas utilziando o SQL para realizar a análise dos dados.\n",
        "\n",
        "2. Aluno:\n",
        "\n",
        "    João Souza - ID do Aluno: 1116027"
      ],
      "metadata": {
        "id": "lbFIpFaWPElS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Realizando a instalação das bibliotecas a serem utilizadas:"
      ],
      "metadata": {
        "id": "bnczpBprUeEQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pandasql\n",
        "!pip install pandas\n",
        "!pip install sqlalchemy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LKEXcufRPNMt",
        "outputId": "120cc4da-e687-4d4b-cda9-7c3cd8ec82a1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pandasql\n",
            "  Downloading pandasql-0.7.3.tar.gz (26 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from pandasql) (1.25.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from pandasql) (1.5.3)\n",
            "Requirement already satisfied: sqlalchemy in /usr/local/lib/python3.10/dist-packages (from pandasql) (2.0.28)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->pandasql) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->pandasql) (2023.4)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy->pandasql) (4.10.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy->pandasql) (3.0.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->pandasql) (1.16.0)\n",
            "Building wheels for collected packages: pandasql\n",
            "  Building wheel for pandasql (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pandasql: filename=pandasql-0.7.3-py3-none-any.whl size=26771 sha256=eb8d3af0f2d84c11f7a5f2a007544b0ab1e8290ee0d02e8eb4509d7f8041ac24\n",
            "  Stored in directory: /root/.cache/pip/wheels/e9/bc/3a/8434bdcccf5779e72894a9b24fecbdcaf97940607eaf4bcdf9\n",
            "Successfully built pandasql\n",
            "Installing collected packages: pandasql\n",
            "Successfully installed pandasql-0.7.3\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.4)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.25.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
            "Requirement already satisfied: sqlalchemy in /usr/local/lib/python3.10/dist-packages (2.0.28)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy) (4.10.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy) (3.0.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Importando as bibliotecas\n",
        ">Serão utilizadas as bibliotecas Numpy e Pandas para manipulação dos dados presentes no Dataset.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Ga5O4OXnUnwO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sqlalchemy import create_engine\n",
        "import pandas as pd\n",
        "import pandasql as ps"
      ],
      "metadata": {
        "id": "7CWCc8OYQPPv"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Criação das tabelas no pgAdmin4\n",
        "Com os arquivos do Dataset em mãos, agora partiremos para a criação das tabelas dentro do pgAdmin4. Para tal, devemos fazer a declaração das colunas e suas tipagens utilizando SQL, como abaixo:\n",
        "\n",
        "*É importante a criação do schema para o projeto, que nesse caso teve o nome de db_project."
      ],
      "metadata": {
        "id": "Duyaf1iXVCf5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "```\n",
        "CREATE TABLE db_project.customers(\n",
        "\tcustomer_id VARCHAR(255),\n",
        "\tcustomer_unique_id VARCHAR(255),\n",
        "\tcustomer_zip_code_prefix INT,\n",
        "\tcustomer_city VARCHAR(255),\n",
        "\tcustomer_state VARCHAR(30)\n",
        ");\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "u-4dx5WtSJH3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Após a execução desse comando, será criada a tabela customers e será possível importar os dados presentes no Dataset declarado através do pgAdmin4, com isso faremos o mesmo com as demais tabelas presentes no Dataset para realizar as análises com todos os dados."
      ],
      "metadata": {
        "id": "hJsFonmEWLLx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "8EiUSworWrsH"
      }
    }
  ]
}